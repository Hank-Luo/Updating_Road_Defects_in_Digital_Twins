{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7044cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  1.10 ; cuda:  1.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25dfb806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a87bcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/28 16:21:19 d2.data.datasets.coco]: Loaded 13 images in COCO format from cropped_images/train_depth.json\n"
     ]
    }
   ],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "register_coco_instances(\"road_defect_detection_train\", {}, \"cropped_images/train_depth.json\", \"cropped_images/train_depth\")\n",
    "register_coco_instances(\"road_defect_detection_val\", {}, \"cropped_images/depth_09/annotations/instances_default.json\", \"cropped_images/depth_09/images\")\n",
    "\n",
    "my_dataset_train_metadata = MetadataCatalog.get(\"road_defect_detection_train\")\n",
    "dataset_dicts = DatasetCatalog.get(\"road_defect_detection_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "414923bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 1\n",
    "cfg.MODEL.WEIGHTS = 'depth_model_0000749.pth'\n",
    "cfg.DATASETS.TRAIN = (\"road_defect_detection_train\",)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "643fd5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cropped_images/depth_09/images\\tile_09_depth_0_0.png\n",
      "cropped_images/depth_09/images\\tile_09_depth_0_1600.png\n",
      "cropped_images/depth_09/images\\tile_09_depth_0_2400.png\n",
      "cropped_images/depth_09/images\\tile_09_depth_0_3200.png\n",
      "cropped_images/depth_09/images\\tile_09_depth_0_4000.png\n",
      "cropped_images/depth_09/images\\tile_09_depth_0_5600.png\n",
      "cropped_images/depth_09/images\\tile_09_depth_0_6400.png\n",
      "cropped_images/depth_09/images\\tile_09_depth_0_7200.png\n",
      "cropped_images/depth_09/images\\tile_09_depth_0_800.png\n",
      "cropped_images/depth_09/images\\tile_09_depth_0_8000.png\n",
      "cropped_images/depth_09/images\\tile_09_depth_0_8800.png\n"
     ]
    }
   ],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "# import matplotlib.pyplot as plt\n",
    "test_path = \"cropped_images/depth_09/images\"\n",
    "\n",
    "for filename in os.listdir(test_path):\n",
    "    f = os.path.join(test_path, filename)\n",
    "    print(f)\n",
    "    im = cv2.imread(f)\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    out_filename = filename[:-4] + \"_out.png\"\n",
    "    cv2.imwrite(out_filename, v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207b8878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/28 16:23:35 d2.data.datasets.coco]: Loaded 11 images in COCO format from cropped_images/depth_09/annotations/instances_default.json\n",
      "[05/28 16:23:36 d2.data.build]: Distribution of instances among all 1 categories:\n",
      "|  category  | #instances   |\n",
      "|:----------:|:-------------|\n",
      "|  Potholes  | 49           |\n",
      "|            |              |\n",
      "[05/28 16:23:36 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "[05/28 16:23:36 d2.data.common]: Serializing 11 elements to byte tensors and concatenating them all ...\n",
      "[05/28 16:23:36 d2.data.common]: Serialized dataset takes 0.01 MiB\n",
      "[05/28 16:23:36 d2.evaluation.evaluator]: Start inference on 11 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luope\\Anaconda3\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/28 16:23:51 d2.evaluation.evaluator]: Inference done 1/11. Dataloading: 9.5706 s/iter. Inference: 5.7427 s/iter. Eval: 0.0001 s/iter. Total: 15.3139 s/iter. ETA=0:02:33\n",
      "[05/28 16:23:53 d2.evaluation.evaluator]: Total inference time: 0:00:01.693689 (0.282281 s / iter per device, on 1 devices)\n",
      "[05/28 16:23:53 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:01 (0.223845 s / iter per device, on 1 devices)\n",
      "[05/28 16:23:53 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
      "[05/28 16:23:53 d2.evaluation.coco_evaluation]: Saving results to ./output\\coco_instances_results.json\n",
      "[05/28 16:23:53 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "[05/28 16:23:53 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
      "[05/28 16:23:53 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.00 seconds.\n",
      "[05/28 16:23:53 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[05/28 16:23:54 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.126\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.307\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.050\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.114\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.295\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.082\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.163\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.148\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "[05/28 16:23:54 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl  |\n",
      "|:------:|:------:|:------:|:------:|:------:|:-----:|\n",
      "| 12.567 | 30.694 | 5.025  | 11.418 | 29.455 |  nan  |\n",
      "[05/28 16:23:54 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "[05/28 16:23:54 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
      "[05/28 16:23:54 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.00 seconds.\n",
      "[05/28 16:23:54 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[05/28 16:23:54 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.00 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.092\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.264\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.078\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.264\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.055\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.122\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.107\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.260\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = -1.000\n",
      "[05/28 16:23:54 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm   |  APl  |\n",
      "|:-----:|:------:|:------:|:-----:|:------:|:-----:|\n",
      "| 9.198 | 26.398 | 3.694  | 7.791 | 26.436 |  nan  |\n",
      "[05/28 16:23:54 d2.evaluation.coco_evaluation]: Some metrics cannot be computed and is shown as NaN.\n",
      "OrderedDict([('bbox', {'AP': 12.566586691551876, 'AP50': 30.693657994562003, 'AP75': 5.024998298149143, 'APs': 11.418081945302005, 'APm': 29.455445544554454, 'APl': nan}), ('segm', {'AP': 9.197820880989198, 'AP50': 26.397848576066394, 'AP75': 3.693830921553694, 'APs': 7.790779077907792, 'APm': 26.435643564356436, 'APl': nan})])\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"road_defect_detection_val\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"road_defect_detection_val\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
    "# another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be6c9f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
