{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d7044cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch:  1.10 ; cuda:  1.10.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "TORCH_VERSION = \".\".join(torch.__version__.split(\".\")[:2])\n",
    "CUDA_VERSION = torch.__version__.split(\"+\")[-1]\n",
    "print(\"torch: \", TORCH_VERSION, \"; cuda: \", CUDA_VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25dfb806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "\n",
    "# import some common libraries\n",
    "import numpy as np\n",
    "import os, json, cv2, random\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a87bcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/28 08:23:20 d2.data.datasets.coco]: Loaded 269 images in COCO format from instances_default.json\n"
     ]
    }
   ],
   "source": [
    "from detectron2.data.datasets import register_coco_instances\n",
    "\n",
    "register_coco_instances(\"road_defect_detection_train\", {}, \"instances_default.json\", \"training_images\")\n",
    "register_coco_instances(\"road_defect_detection_val\", {}, \"new_instances.json\", \"validation_images\")\n",
    "\n",
    "my_dataset_train_metadata = MetadataCatalog.get(\"road_defect_detection_train\")\n",
    "dataset_dicts = DatasetCatalog.get(\"road_defect_detection_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "414923bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.ROI_HEADS.NUM_CLASSES = 8\n",
    "cfg.MODEL.WEIGHTS = 'model_final.pth'\n",
    "cfg.DATASETS.TRAIN = (\"road_defect_detection_train\",)\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "643fd5af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "validation_images\\cropped_1.png\n",
      "validation_images\\cropped_10.png\n",
      "validation_images\\cropped_11.png\n",
      "validation_images\\cropped_12.png\n",
      "validation_images\\cropped_13.png\n",
      "validation_images\\cropped_14.png\n",
      "validation_images\\cropped_15.png\n",
      "validation_images\\cropped_16.png\n",
      "validation_images\\cropped_17.png\n",
      "validation_images\\cropped_18.png\n",
      "validation_images\\cropped_19.png\n",
      "validation_images\\cropped_2.png\n",
      "validation_images\\cropped_20.png\n",
      "validation_images\\cropped_21.png\n",
      "validation_images\\cropped_22.png\n",
      "validation_images\\cropped_23.png\n",
      "validation_images\\cropped_24.png\n",
      "validation_images\\cropped_25.png\n",
      "validation_images\\cropped_26.png\n",
      "validation_images\\cropped_27.png\n",
      "validation_images\\cropped_28.png\n",
      "validation_images\\cropped_29.png\n",
      "validation_images\\cropped_3.png\n",
      "validation_images\\cropped_30.png\n",
      "validation_images\\cropped_31.png\n",
      "validation_images\\cropped_32.png\n",
      "validation_images\\cropped_33.png\n",
      "validation_images\\cropped_34.png\n",
      "validation_images\\cropped_35.png\n",
      "validation_images\\cropped_36.png\n",
      "validation_images\\cropped_37.png\n",
      "validation_images\\cropped_38.png\n",
      "validation_images\\cropped_39.png\n",
      "validation_images\\cropped_4.png\n",
      "validation_images\\cropped_40.png\n",
      "validation_images\\cropped_41.png\n",
      "validation_images\\cropped_42.png\n",
      "validation_images\\cropped_43.png\n",
      "validation_images\\cropped_44.png\n",
      "validation_images\\cropped_45.png\n",
      "validation_images\\cropped_46.png\n",
      "validation_images\\cropped_47.png\n",
      "validation_images\\cropped_48.png\n",
      "validation_images\\cropped_49.png\n",
      "validation_images\\cropped_5.png\n",
      "validation_images\\cropped_50.png\n",
      "validation_images\\cropped_51.png\n",
      "validation_images\\cropped_52.png\n",
      "validation_images\\cropped_53.png\n",
      "validation_images\\cropped_54.png\n",
      "validation_images\\cropped_55.png\n",
      "validation_images\\cropped_56.png\n",
      "validation_images\\cropped_57.png\n",
      "validation_images\\cropped_58.png\n",
      "validation_images\\cropped_59.png\n",
      "validation_images\\cropped_6.png\n",
      "validation_images\\cropped_60.png\n",
      "validation_images\\cropped_61.png\n",
      "validation_images\\cropped_62.png\n",
      "validation_images\\cropped_63.png\n",
      "validation_images\\cropped_64.png\n",
      "validation_images\\cropped_65.png\n",
      "validation_images\\cropped_66.png\n",
      "validation_images\\cropped_67.png\n",
      "validation_images\\cropped_68.png\n",
      "validation_images\\cropped_7.png\n",
      "validation_images\\cropped_8.png\n",
      "validation_images\\cropped_9.png\n"
     ]
    }
   ],
   "source": [
    "from detectron2.utils.visualizer import ColorMode\n",
    "# import matplotlib.pyplot as plt\n",
    "test_path = \"validation_images\"\n",
    "\n",
    "for filename in os.listdir(test_path):\n",
    "    f = os.path.join(test_path, filename)\n",
    "    print(f)\n",
    "    im = cv2.imread(f)\n",
    "    outputs = predictor(im)\n",
    "    v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    out_filename = filename[:-4] + \"_out.jpg\"\n",
    "    cv2.imwrite(out_filename, v.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "207b8878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/28 08:23:32 d2.data.datasets.coco]: Loaded 68 images in COCO format from new_instances.json\n",
      "[05/28 08:23:32 d2.data.build]: Distribution of instances among all 8 categories:\n",
      "|  category  | #instances   |   category    | #instances   |   category    | #instances   |\n",
      "|:----------:|:-------------|:-------------:|:-------------|:-------------:|:-------------|\n",
      "|   Cracks   | 31           |   Potholes    | 33           |    Patches    | 0            |\n",
      "|  Sidewalk  | 0            | White Road .. | 0            | Double Yell.. | 0            |\n",
      "|    Car     | 0            | Alligator C.. | 4            |               |              |\n",
      "|   total    | 68           |               |              |               |              |\n",
      "[05/28 08:23:32 d2.data.dataset_mapper]: [DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]\n",
      "[05/28 08:23:32 d2.data.common]: Serializing 68 elements to byte tensors and concatenating them all ...\n",
      "[05/28 08:23:32 d2.data.common]: Serialized dataset takes 0.03 MiB\n",
      "[05/28 08:23:32 d2.evaluation.evaluator]: Start inference on 68 batches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\luope\\Anaconda3\\lib\\site-packages\\torch\\functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ..\\aten\\src\\ATen\\native\\TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[05/28 08:23:50 d2.evaluation.evaluator]: Inference done 1/68. Dataloading: 10.0837 s/iter. Inference: 8.3632 s/iter. Eval: 0.0012 s/iter. Total: 18.4486 s/iter. ETA=0:20:36\n",
      "[05/28 08:23:55 d2.evaluation.evaluator]: Inference done 24/68. Dataloading: 0.0006 s/iter. Inference: 0.2210 s/iter. Eval: 0.0010 s/iter. Total: 0.2226 s/iter. ETA=0:00:09\n",
      "[05/28 08:24:00 d2.evaluation.evaluator]: Inference done 47/68. Dataloading: 0.0006 s/iter. Inference: 0.2188 s/iter. Eval: 0.0009 s/iter. Total: 0.2204 s/iter. ETA=0:00:04\n",
      "[05/28 08:24:05 d2.evaluation.evaluator]: Total inference time: 0:00:13.969117 (0.221732 s / iter per device, on 1 devices)\n",
      "[05/28 08:24:05 d2.evaluation.evaluator]: Total inference pure compute time: 0:00:13 (0.215731 s / iter per device, on 1 devices)\n",
      "[05/28 08:24:05 d2.evaluation.coco_evaluation]: Preparing results for COCO format ...\n",
      "[05/28 08:24:05 d2.evaluation.coco_evaluation]: Saving results to ./output\\coco_instances_results.json\n",
      "[05/28 08:24:05 d2.evaluation.coco_evaluation]: Evaluating predictions with unofficial COCO API...\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "[05/28 08:24:05 d2.evaluation.fast_eval_api]: Evaluate annotation type *bbox*\n",
      "[05/28 08:24:05 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.02 seconds.\n",
      "[05/28 08:24:05 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[05/28 08:24:05 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.03 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.155\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.381\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.144\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.103\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.111\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.218\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.246\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.147\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.204\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.338\n",
      "[05/28 08:24:05 d2.evaluation.coco_evaluation]: Evaluation results for bbox: \n",
      "|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |\n",
      "|:------:|:------:|:------:|:------:|:------:|:------:|\n",
      "| 15.505 | 38.125 | 14.436 | 10.293 | 11.140 | 22.760 |\n",
      "[05/28 08:24:05 d2.evaluation.coco_evaluation]: Per-category bbox AP: \n",
      "| category   | AP     | category            | AP     | category           | AP   |\n",
      "|:-----------|:-------|:--------------------|:-------|:-------------------|:-----|\n",
      "| Cracks     | 10.721 | Potholes            | 8.854  | Patches            | nan  |\n",
      "| Sidewalk   | nan    | White Road Markings | nan    | Double Yellow line | nan  |\n",
      "| Car        | nan    | Alligator Cracks    | 26.942 |                    |      |\n",
      "Loading and preparing results...\n",
      "DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "[05/28 08:24:05 d2.evaluation.fast_eval_api]: Evaluate annotation type *segm*\n",
      "[05/28 08:24:05 d2.evaluation.fast_eval_api]: COCOeval_opt.evaluate() finished in 0.08 seconds.\n",
      "[05/28 08:24:05 d2.evaluation.fast_eval_api]: Accumulating evaluation results...\n",
      "[05/28 08:24:05 d2.evaluation.fast_eval_api]: COCOeval_opt.accumulate() finished in 0.02 seconds.\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.087\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.201\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.037\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.027\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.083\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.174\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.123\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.135\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.135\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.088\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.143\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.250\n",
      "[05/28 08:24:05 d2.evaluation.coco_evaluation]: Evaluation results for segm: \n",
      "|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl   |\n",
      "|:-----:|:------:|:------:|:-----:|:-----:|:------:|\n",
      "| 8.739 | 20.110 | 3.690  | 2.676 | 8.342 | 17.444 |\n",
      "[05/28 08:24:05 d2.evaluation.coco_evaluation]: Per-category segm AP: \n",
      "| category   | AP    | category            | AP     | category           | AP   |\n",
      "|:-----------|:------|:--------------------|:-------|:-------------------|:-----|\n",
      "| Cracks     | 3.968 | Potholes            | 9.377  | Patches            | nan  |\n",
      "| Sidewalk   | nan   | White Road Markings | nan    | Double Yellow line | nan  |\n",
      "| Car        | nan   | Alligator Cracks    | 12.871 |                    |      |\n",
      "OrderedDict([('bbox', {'AP': 15.50548360432005, 'AP50': 38.12517758967891, 'AP75': 14.436375624853303, 'APs': 10.292904290429043, 'APm': 11.14034344777373, 'APl': 22.760490334747757, 'AP-Cracks': 10.720670911763834, 'AP-Potholes': 8.854085731779382, 'AP-Patches': nan, 'AP-Sidewalk': nan, 'AP-White Road Markings': nan, 'AP-Double Yellow line': nan, 'AP-Car': nan, 'AP-Alligator Cracks': 26.94169416941694}), ('segm', {'AP': 8.738861711690435, 'AP50': 20.109895468429734, 'AP75': 3.6895286167272188, 'APs': 2.6760176017601762, 'APm': 8.34240637626547, 'APl': 17.443776520509196, 'AP-Cracks': 3.968021962658396, 'AP-Potholes': 9.37727604370004, 'AP-Patches': nan, 'AP-Sidewalk': nan, 'AP-White Road Markings': nan, 'AP-Double Yellow line': nan, 'AP-Car': nan, 'AP-Alligator Cracks': 12.871287128712872})])\n"
     ]
    }
   ],
   "source": [
    "from detectron2.evaluation import COCOEvaluator, inference_on_dataset\n",
    "from detectron2.data import build_detection_test_loader\n",
    "evaluator = COCOEvaluator(\"road_defect_detection_val\", output_dir=\"./output\")\n",
    "val_loader = build_detection_test_loader(cfg, \"road_defect_detection_val\")\n",
    "print(inference_on_dataset(predictor.model, val_loader, evaluator))\n",
    "# another equivalent way to evaluate the model is to use `trainer.test`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c309214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'instances': Instances(num_instances=2, image_height=276, image_width=583, fields=[pred_boxes: Boxes(tensor([[ 32.3418,  94.9284, 530.5706, 190.1936],\n",
      "        [ 35.2642,   4.0985,  96.4415,  57.9806]], device='cuda:0')), scores: tensor([0.9740, 0.8684], device='cuda:0'), pred_classes: tensor([1, 0], device='cuda:0'), pred_masks: tensor([[[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]],\n",
      "\n",
      "        [[False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         ...,\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False],\n",
      "         [False, False, False,  ..., False, False, False]]], device='cuda:0')])}\n"
     ]
    }
   ],
   "source": [
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4c460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path = \"validation_images\"\n",
    "with open(\"new_instances.json\", \"r\") as read_file:\n",
    "    instances = json.load(read_file)\n",
    "\n",
    "for filename in os.listdir(test_path):\n",
    "    i = 0\n",
    "    f = os.path.join(test_path, filename)\n",
    "    print(f)\n",
    "    im = cv2.imread(f)\n",
    "    outputs = instances[\"annotations\"][i]\n",
    "    v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n",
    "    v = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "    out_filename = filename[:-4] + \"_out.jpg\"\n",
    "    cv2.imwrite(out_filename, v.get_image()[:, :, ::-1])\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
